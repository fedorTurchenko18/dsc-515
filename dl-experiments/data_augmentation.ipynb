{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Environment (default operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tensorflow as tf, json, matplotlib.pyplot as plt\n",
    "from data_loader.hgf_export import HGFresource\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HGF_TOKEN = os.environ['HUGGINGFACE_TOKEN']\n",
    "HGF_DATA_REPO = os.environ['HUGGINGFACE_DATASET_V2_REPO']\n",
    "HGF_BASELINE_MODEL_REPO = os.environ['HUGGINGFACE_BASELINE_CNN_REPO']\n",
    "HGF_BASELINE_MODEL_CONFIG = os.environ['HUGGINGFACE_BASELINE_CNN_CONFIG_FILE']\n",
    "HGF_BASELINE_MODEL_WEIGHTS = os.environ['HUGGINGFACE_BASELINE_CNN_WEIGHTS_FILE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgf = HGFresource(token=HGF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config of baseline model which we need to optimize\n",
    "model_config_file = hgf.load_file(repo=HGF_BASELINE_MODEL_REPO, filename=HGF_BASELINE_MODEL_CONFIG)\n",
    "with open(model_config_file, 'r') as f:\n",
    "    model_config = f.read()\n",
    "model_config = json.loads(model_config)\n",
    "# extract number of classes from the last layer\n",
    "N_CLASSES = model_config['layers'][-1]['config']['units']\n",
    "\n",
    "# # alternatively, you can load the full baseline model with pre-defined weights\n",
    "# # you may want to do this for the sake of performance comparison\n",
    "# # but note that you will occupy additional RAM space (without a good reason probably)\n",
    "baseline_model = hgf.load_model(\n",
    "    repo=HGF_BASELINE_MODEL_REPO,\n",
    "    filename={\n",
    "        'model_weights': HGF_BASELINE_MODEL_WEIGHTS,\n",
    "        'model_config': HGF_BASELINE_MODEL_CONFIG\n",
    "    }\n",
    ")\n",
    "# # extract number of classes from the last layer\n",
    "# N_CLASSES = baseline_model.layers[-1].get_config()['units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d460f47e2e09421994b551efc0dadb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8211012d37462e8c1b8f037f101b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d8310f4d9a4fc189487f81e5ff6223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b7f409306a4f359c705c11f51a614c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/81.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ae9b4b7f6848a1a581845f0c67828b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bada54187e4514995b09a665fee1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/40989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3aff94baeb4bf49abb373a3caef474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/13663 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ab1624f475419098da338206cda777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431080c859c34b38923edae066ae4a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13663 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data, test_data = hgf.load_data_tfds(repo=HGF_DATA_REPO, n_classes=N_CLASSES, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate may require fine-tuning but use the optimizer specified below\n",
    "# OPTIMIZER = tf.keras.optimizers.legacy.Adam(learning_rate=0.001) # use this if you have M1/M2 Mac, otherwise use the next line\n",
    "# OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "LOSS = 'categorical_crossentropy'\n",
    "METRICS = [tf.keras.metrics.F1Score('weighted')]\n",
    "EPOCHS = 20\n",
    "INPUT_SHAPE = (256, 219, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the baseline model architecture\n",
    "model = tf.keras.Sequential.from_config(model_config)\n",
    "# view the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_plot(history):\n",
    "    train_f1_scores = history.history['f1_score']\n",
    "    val_f1_scores = history.history['val_f1_score']\n",
    "\n",
    "    epochs = range(1, len(train_f1_scores) + 1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_f1_scores, 'bo-', label='Training F1 Score')\n",
    "    plt.plot(epochs, val_f1_scores, 'ro-', label='Validation F1 Score')\n",
    "    plt.title('Training and Validation F1 Score')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Code Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some fancy stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commit Your Results to Hugging Face Once Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: when naming your weights file\n",
    "# indicate the type of model\n",
    "# e.g.:\n",
    "## 'tuned_optimizer_model_weights.h5'\n",
    "## 'data_augmentation_model_weights.h5'\n",
    "WEIGHTS_TO_COMMIT = '<your_name>_model_weights.h5'\n",
    "# save model weights\n",
    "model.save_weights(WEIGHTS_TO_COMMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERFORMANCE_TO_COMMIT = '<your_name_same_as_for_weights>_model_performance.json'\n",
    "performance_dict = {\n",
    "    'train': {\n",
    "        'weighted_f1': history.history['f1_score'][-1]\n",
    "    },\n",
    "    'test': {\n",
    "        'weighted_f1': history.history['val_f1_score'][-1]\n",
    "    }\n",
    "}\n",
    "performance_dict = json.dumps(performance_dict)\n",
    "with open(PERFORMANCE_TO_COMMIT, 'w') as f:\n",
    "    f.write(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgf.commit_to_hub(\n",
    "    repo=HGF_BASELINE_MODEL_REPO,\n",
    "    path_on_local=[WEIGHTS_TO_COMMIT, PERFORMANCE_TO_COMMIT],\n",
    "    path_in_repo=[WEIGHTS_TO_COMMIT, PERFORMANCE_TO_COMMIT],\n",
    "    # do not forget to change your commit message\n",
    "    # to add even more clarity\n",
    "    commit_message='your commit message'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove files from local = clean up\n",
    "for path in [WEIGHTS_TO_COMMIT, PERFORMANCE_TO_COMMIT]:\n",
    "    os.remove(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
