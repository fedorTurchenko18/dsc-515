{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Environment (default operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panikos = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, tensorflow as tf, json, matplotlib.pyplot as plt\n",
    "\n",
    "if panikos:\n",
    "    from data_loader.hgf_export_Pan import HGFresource\n",
    "else:\n",
    "    from data_loader.hgf_export import HGFresource\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HGF_TOKEN = os.environ['HUGGINGFACE_TOKEN']\n",
    "HGF_DATA_REPO = os.environ['HUGGINGFACE_DATASET_V2_REPO']\n",
    "HGF_BASELINE_MODEL_REPO = os.environ['HUGGINGFACE_BASELINE_CNN_REPO']\n",
    "HGF_BASELINE_MODEL_CONFIG = os.environ['HUGGINGFACE_BASELINE_CNN_CONFIG_FILE']\n",
    "HGF_BASELINE_MODEL_WEIGHTS = os.environ['HUGGINGFACE_BASELINE_CNN_WEIGHTS_FILE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hgf = HGFresource(token=HGF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load config of baseline model which we need to optimize\n",
    "model_config_file = hgf.load_file(repo=HGF_BASELINE_MODEL_REPO, filename=HGF_BASELINE_MODEL_CONFIG)\n",
    "with open(model_config_file, 'r') as f:\n",
    "    model_config = f.read()\n",
    "model_config = json.loads(model_config)\n",
    "# extract number of classes from the last layer\n",
    "N_CLASSES = model_config['layers'][-1]['config']['units']\n",
    "\n",
    "# # alternatively, you can load the full baseline model with pre-defined weights\n",
    "# # you may want to do this for the sake of performance comparison\n",
    "# # but note that you will occupy additional RAM space (without a good reason probably)\n",
    "baseline_model = hgf.load_model(\n",
    "    repo=HGF_BASELINE_MODEL_REPO,\n",
    "    filename={\n",
    "        'model_weights': HGF_BASELINE_MODEL_WEIGHTS,\n",
    "        'model_config': HGF_BASELINE_MODEL_CONFIG\n",
    "    }\n",
    ")\n",
    "# # extract number of classes from the last layer\n",
    "# N_CLASSES = baseline_model.layers[-1].get_config()['units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5560feee06ef4fffbde93c5862ec54cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13663 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data, test_data = hgf.load_data_tfds(repo=HGF_DATA_REPO, n_classes=N_CLASSES, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# learning rate may require fine-tuning but use the optimizer specified below\n",
    "# OPTIMIZER = tf.keras.optimizers.legacy.Adam(learning_rate=0.001) # use this if you have M1/M2 Mac, otherwise use the next line\n",
    "# OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "LOSS = 'categorical_crossentropy'\n",
    "\n",
    "if panikos:\n",
    "    METRICS = [tf.keras.metrics.CategoricalAccuracy()]\n",
    "else:\n",
    "    METRICS = [tf.keras.metrics.F1Score('weighted')]\n",
    "    \n",
    "EPOCHS = 20\n",
    "INPUT_SHAPE = (256, 219, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 254, 217, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 127, 108, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 125, 106, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 62, 53, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 60, 51, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 30, 25, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 48000)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               6144128   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 57)                7353      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,175,065\n",
      "Trainable params: 6,175,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initialize the baseline model architecture\n",
    "model = tf.keras.Sequential.from_config(model_config)\n",
    "# view the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss=LOSS,metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def history_plot(history):\n",
    "    train_f1_scores = history.history['f1_score']\n",
    "    val_f1_scores = history.history['val_f1_score']\n",
    "\n",
    "    epochs = range(1, len(train_f1_scores) + 1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_f1_scores, 'bo-', label='Training F1 Score')\n",
    "    plt.plot(epochs, val_f1_scores, 'ro-', label='Validation F1 Score')\n",
    "    plt.title('Training and Validation F1 Score')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Code Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some fancy stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1281/1281 [==============================] - 189s 115ms/step - loss: 1.6341 - categorical_accuracy: 0.6310 - val_loss: 0.9419 - val_categorical_accuracy: 0.7606\n",
      "Epoch 2/20\n",
      "1281/1281 [==============================] - 135s 105ms/step - loss: 0.6529 - categorical_accuracy: 0.8258 - val_loss: 0.6182 - val_categorical_accuracy: 0.8363\n",
      "Epoch 3/20\n",
      "1281/1281 [==============================] - 133s 104ms/step - loss: 0.4607 - categorical_accuracy: 0.8716 - val_loss: 0.5385 - val_categorical_accuracy: 0.8574\n",
      "Epoch 4/20\n",
      "1281/1281 [==============================] - 166s 129ms/step - loss: 0.3721 - categorical_accuracy: 0.8910 - val_loss: 0.5276 - val_categorical_accuracy: 0.8534\n",
      "Epoch 5/20\n",
      "1281/1281 [==============================] - 150s 117ms/step - loss: 0.3212 - categorical_accuracy: 0.9033 - val_loss: 0.5081 - val_categorical_accuracy: 0.8653\n",
      "Epoch 6/20\n",
      "1281/1281 [==============================] - 140s 109ms/step - loss: 0.2866 - categorical_accuracy: 0.9132 - val_loss: 0.5094 - val_categorical_accuracy: 0.8666\n",
      "Epoch 7/20\n",
      "1281/1281 [==============================] - 143s 112ms/step - loss: 0.2676 - categorical_accuracy: 0.9191 - val_loss: 0.6020 - val_categorical_accuracy: 0.8664\n",
      "Epoch 8/20\n",
      "1281/1281 [==============================] - 155s 121ms/step - loss: 0.2494 - categorical_accuracy: 0.9254 - val_loss: 0.5066 - val_categorical_accuracy: 0.8718\n",
      "Epoch 9/20\n",
      "1281/1281 [==============================] - 150s 117ms/step - loss: 0.2344 - categorical_accuracy: 0.9306 - val_loss: 0.5198 - val_categorical_accuracy: 0.8689\n",
      "Epoch 10/20\n",
      "1281/1281 [==============================] - 154s 120ms/step - loss: 0.2162 - categorical_accuracy: 0.9360 - val_loss: 0.5451 - val_categorical_accuracy: 0.8660\n",
      "Epoch 11/20\n",
      "1281/1281 [==============================] - 148s 116ms/step - loss: 0.2118 - categorical_accuracy: 0.9365 - val_loss: 0.5251 - val_categorical_accuracy: 0.8580\n",
      "Epoch 12/20\n",
      "1281/1281 [==============================] - 144s 112ms/step - loss: 0.2033 - categorical_accuracy: 0.9400 - val_loss: 0.6129 - val_categorical_accuracy: 0.8728\n",
      "Epoch 13/20\n",
      "1281/1281 [==============================] - 142s 110ms/step - loss: 0.2030 - categorical_accuracy: 0.9412 - val_loss: 0.5704 - val_categorical_accuracy: 0.8724\n",
      "Epoch 14/20\n",
      "1281/1281 [==============================] - 142s 111ms/step - loss: 0.2023 - categorical_accuracy: 0.9432 - val_loss: 0.8052 - val_categorical_accuracy: 0.8682\n",
      "Epoch 15/20\n",
      "1281/1281 [==============================] - 142s 110ms/step - loss: 0.2157 - categorical_accuracy: 0.9425 - val_loss: 0.6878 - val_categorical_accuracy: 0.8662\n",
      "Epoch 16/20\n",
      "1281/1281 [==============================] - 143s 112ms/step - loss: 0.1946 - categorical_accuracy: 0.9449 - val_loss: 0.8381 - val_categorical_accuracy: 0.8662\n",
      "Epoch 17/20\n",
      "1281/1281 [==============================] - 144s 113ms/step - loss: 0.1885 - categorical_accuracy: 0.9469 - val_loss: 0.7376 - val_categorical_accuracy: 0.8451\n",
      "Epoch 18/20\n",
      "1281/1281 [==============================] - 145s 113ms/step - loss: 0.1967 - categorical_accuracy: 0.9469 - val_loss: 0.8690 - val_categorical_accuracy: 0.8716\n",
      "Epoch 19/20\n",
      "1281/1281 [==============================] - 162s 126ms/step - loss: 0.1923 - categorical_accuracy: 0.9478 - val_loss: 0.7873 - val_categorical_accuracy: 0.8655\n",
      "Epoch 20/20\n",
      "1281/1281 [==============================] - 164s 128ms/step - loss: 0.2207 - categorical_accuracy: 0.9481 - val_loss: 0.7428 - val_categorical_accuracy: 0.8730\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commit Your Results to Hugging Face Once Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: when naming your weights file\n",
    "# indicate the type of model\n",
    "# e.g.:\n",
    "## 'tuned_optimizer_model_weights.h5'\n",
    "## 'data_augmentation_model_weights.h5'\n",
    "WEIGHTS_TO_COMMIT = '<your_name>_model_weights.h5'\n",
    "# save model weights\n",
    "model.save_weights(WEIGHTS_TO_COMMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERFORMANCE_TO_COMMIT = '<your_name_same_as_for_weights>_model_performance.json'\n",
    "\n",
    "\n",
    "if panikos:\n",
    "       performance_dict = {\n",
    "        'train': {\n",
    "            'weighted_f1': history.history['categorical_accuracy'][-1]\n",
    "        },\n",
    "        'test': {\n",
    "            'weighted_f1': history.history['val_categorical_accuracy'][-1]\n",
    "            }\n",
    "    }\n",
    "else:\n",
    "    performance_dict = {\n",
    "        'train': {\n",
    "            'weighted_f1': history.history['f1_score'][-1]\n",
    "        },\n",
    "        'test': {\n",
    "            'weighted_f1': history.history['val_f1_score'][-1]\n",
    "            }\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "performance_dict = json.dumps(performance_dict)\n",
    "with open(PERFORMANCE_TO_COMMIT, 'w') as f:\n",
    "    f.write(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgf.commit_to_hub(\n",
    "    repo=HGF_BASELINE_MODEL_REPO,\n",
    "    path_on_local=[WEIGHTS_TO_COMMIT, PERFORMANCE_TO_COMMIT],\n",
    "    path_in_repo=[WEIGHTS_TO_COMMIT, PERFORMANCE_TO_COMMIT],\n",
    "    # do not forget to change your commit message\n",
    "    # to add even more clarity\n",
    "    commit_message='your commit message'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove files from local = clean up\n",
    "for path in [WEIGHTS_TO_COMMIT, PERFORMANCE_TO_COMMIT]:\n",
    "    os.remove(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
