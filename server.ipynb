{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ed19eb-08f8-433c-914a-4cb1563060c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a349cc-dc7f-4ed6-a41c-0c6237ad0f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a41d73be-0ad3-4777-8d93-c63ac4295433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.8 ms ± 4.52 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n",
      "10.2 ms ± 4.52 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "x = np.random.rand(1000,1000)\n",
    "y = jnp.array(x)\n",
    "\n",
    "def f(x):\n",
    "\n",
    "  for _ in range(10):\n",
    "      x = 0.5*x + 0.1* jnp.sin(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "g = jit(f)\n",
    "\n",
    "%timeit -n 5 -r 5 f(y).block_until_ready()\n",
    "# 5 loops, best of 5: 10.8 ms per loop\n",
    "\n",
    "%timeit -n 5 -r 5 g(y).block_until_ready()\n",
    "# 5 loops, best of 5: 341 µs per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1a2d36d-8e21-4445-a5b6-579d18a8f2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import flwr\n",
    "print(flwr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf73c44-7163-478f-83b8-a95b354be617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "\n",
    "\n",
    "# Define Flower client for TensorFlow\n",
    "class TensorFlowClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, dataset, epochs=1, batch_size=32):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    def get_parameters(self):\n",
    "        # Convert model parameters to a list of NumPy ndarrays\n",
    "        return [np.asarray(v) for v in self.model.get_weights()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        # Set model parameters from a list of NumPy ndarrays\n",
    "        self.model.set_weights(parameters)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        # Set the parameters, train the model, return the updated parameters\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.fit(self.dataset[0], self.dataset[1], epochs=self.epochs, batch_size=self.batch_size)\n",
    "        return self.get_parameters(), len(self.dataset[0]), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        # Set the parameters, evaluate the model, return the result\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = self.model.evaluate(self.dataset[0], self.dataset[1])\n",
    "        return float(loss), len(self.dataset[0]), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "# Define Flower client for JAX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25ebd8-a839-42c2-b6f5-d1eeee61b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VGG16 model for TensorFlow\n",
    "tf_model = tf.keras.applications.VGG16(weights=None, input_shape=(224, 224, 3), classes=10)\n",
    "\n",
    "\n",
    "# # For demonstration purposes, let's use a dummy dataset\n",
    "# x_train = np.random.rand(1000, 28, 28)\n",
    "# y_train = np.random.randint(10, size=1000)\n",
    "\n",
    "# # Create an instance of the TensorFlowClient\n",
    "# client = TensorFlowClient(tf_model, (x_train, y_train))\n",
    "\n",
    "# # Start Flower server and client\n",
    "# fl.server.start_server(\"[::]:8080\", config={\"num_rounds\": 3}, strategy=fl.server.strategy.FedAvg())\n",
    "# fl.client.start_numpy_client(\"[::]:8080\", client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe6d61e-dcc4-4820-ac39-4f37f0039c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class PyTorchClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, device, train_loader, test_loader, epochs=1, batch_size=32):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "\n",
    "    def get_parameters(self):\n",
    "        # Convert model parameters to a list of NumPy ndarrays\n",
    "        return [param.cpu().numpy() for param in self.model.parameters()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        # Set model parameters from a list of NumPy ndarrays\n",
    "        params = [torch.from_numpy(p).to(self.device) for p in parameters]\n",
    "        for p, param in zip(self.model.parameters(), params):\n",
    "            p.data = param\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = F.cross_entropy(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        return self.get_parameters(), len(self.train_loader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50ec99-d54e-48ab-9509-de9434fdb635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VGG16 model for PyTorch\n",
    "torch_model = models.vgg16(pretrained=True)\n",
    "torch_model.classifier[6] = torch.nn.Linear(4096, 10)\n",
    "#modify to have 10 classes\n",
    "\n",
    "# # Assuming your PyTorch model is named 'PyTorchModel'\n",
    "# model = PyTorchModel().to(device)\n",
    "\n",
    "# # Prepare dataset\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# # Create an instance of the PyTorchClient\n",
    "# client = PyTorchClient(torch_model, device, train_loader, test_loader)\n",
    "\n",
    "# # Start Flower server and client\n",
    "# fl.server.start_server(\"[::]:8080\", config={\"num_rounds\": 3}, strategy=fl.server.strategy.FedAvg())\n",
    "# fl.client.start_numpy_client(\"[::]:8080\", client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c0b33-e53a-41c4-a683-4867b46d0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit, vmap\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class JAXClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, params, dataset, rng, epochs=1, batch_size=32):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.dataset = dataset\n",
    "        self.rng = rng\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.opt_state = self.create_optimizer()\n",
    "\n",
    "    def create_optimizer(self):\n",
    "        # Define optimizer and initialize optimizer state\n",
    "        optimizer_def = flax.optim.Momentum(learning_rate=0.01, beta=0.9)\n",
    "        return optimizer_def.create(self.params)\n",
    "\n",
    "    def get_parameters(self):\n",
    "        # Convert model parameters to a list of NumPy ndarrays\n",
    "        return flax.serialization.to_state_dict(self.params)\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        # Set model parameters from a list of NumPy ndarrays\n",
    "        self.params = flax.serialization.from_state_dict(self.params, parameters)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        for epoch in range(self.epochs):\n",
    "            for batch in self.dataset:\n",
    "                self.rng, rng_input = random.split(self.rng)\n",
    "                grads = self.get_grads(rng_input, batch)\n",
    "                self.opt_state = self.update(self.opt_state, grads)\n",
    "        return self.get_parameters(), len(self.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        accuracy = self.compute_accuracy(self.dataset)\n",
    "        return float(1 - accuracy), len(self.dataset), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "    @jit\n",
    "    def get_grads(self, rng, batch):\n",
    "        # Compute gradients for a given batch\n",
    "        def loss_fn(params):\n",
    "            logits = self.model.apply({'params': params}, rng, batch[0])\n",
    "            loss = jnp.mean(nn.softmax_cross_entropy(logits=logits, labels=batch[1]))\n",
    "            return loss\n",
    "        grads = grad(loss_fn)(self.params)\n",
    "        return grads\n",
    "\n",
    "    @jit\n",
    "    def update(self, opt_state, grads):\n",
    "        # Update optimizer state using computed gradients\n",
    "        return self.optimizer.update(grads, opt_state)\n",
    "\n",
    "    @jit\n",
    "    def compute_accuracy(self, dataset):\n",
    "        # Compute accuracy for the given dataset\n",
    "        logits = self.model.apply({'params': self.params}, self.rng, dataset[0])\n",
    "        predicted_class = jnp.argmax(logits, axis=1)\n",
    "        return jnp.mean(predicted_class == dataset[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952cbe7-005e-4051-a09d-df63a84faeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16Block(nn.Module):\n",
    "    filters: int\n",
    "    repetitions: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        for _ in range(self.repetitions):\n",
    "            x = nn.Conv(features=self.filters, kernel_size=(3, 3), padding=\"SAME\")(x)\n",
    "            x = nn.relu(x)\n",
    "        return nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    num_classes: int = 1000\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = VGG16Block(filters=64, repetitions=2)(x)\n",
    "        x = VGG16Block(filters=128, repetitions=2)(x)\n",
    "        x = VGG16Block(filters=256, repetitions=3)(x)\n",
    "        x = VGG16Block(filters=512, repetitions=3)(x)\n",
    "        x = VGG16Block(filters=512, repetitions=3)(x)\n",
    "        x = x.reshape((x.shape[0], -1))  # Flatten\n",
    "        x = nn.Dense(features=4096)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=4096)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.num_classes)(x)\n",
    "        return x\n",
    "\n",
    "# Initialize VGG16 model for JAX\n",
    "_, params = VGG16(num_classes=10).init_by_shape(jax.random.PRNGKey(0), [(1, 224, 224, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ff078-462c-4c64-9b7f-d3172c39193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For demonstration purposes, let's use a dummy dataset\n",
    "# x_train = jnp.array(np.random.rand(1000, 28, 28))\n",
    "# y_train = jnp.array(np.random.randint(10, size=1000))\n",
    "\n",
    "# # Create an instance of the JAXClient\n",
    "# client = JAXClient(VGG16(), params, (x_train, y_train), jax.random.PRNGKey(0))\n",
    "\n",
    "# # Start Flower server and client\n",
    "# fl.server.start_server(\"[::]:8080\", config={\"num_rounds\": 3}, strategy=fl.server.strategy.FedAvg())\n",
    "# fl.client.start_numpy_client(\"[::]:8080\", client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37595598-bfe2-4e82-ba8f-4b6d100b42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_with_flower(architecture):\n",
    "    if architecture == 1:\n",
    "        client = PyTorchClient()\n",
    "    elif architecture == 2:\n",
    "        client = TensorFlowClient()\n",
    "    elif architecture == 3:\n",
    "        client = JAXClient()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid architecture choice\")\n",
    "\n",
    "    # Start Flower server and client (for simplicity, running in the same process here)\n",
    "    fl.server.start_server(\"[::]:8080\", config={\"num_rounds\": 3}, strategy=fl.server.strategy.FedAvg())\n",
    "    fl.client.start_numpy_client(\"[::]:8080\", client)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
